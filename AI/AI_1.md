# 1. AI 이해
## 정의
* 정의
  * 사람처럼 행동하도록 만들어진 장치, 소프트웨어
  * 장치가 프로그램을 통해 판단하고 결정을 위한 의사가 있는 것처럼 행동
  * 지능(의사결정)을 인공적(소프트웨어)으로 만들어 냄

* Jonh McCarthy
  * 학습과 기타 다른 지능의 특징을 기계(컴퓨터)가 시뮬레이션 할 수 있는 것

* Patrick Henry Winsto
  * 컴퓨터가 지능을 가질 수 있도록 하는 아이디어를 연구하는 학문
<br><br>
## 인공지능의 부각 이유
* 빅데이터 발달
* 하드웨어 발전으로 인한 정보처리 능력 향상(GPU 등)
* 클라우드 기반 환경 등의 영향을 통한 학습, 추론, 인지 기술 발달
* 딥러닝 알고리즘 향상
<br><br>
## 인공지능의 분류
| 강 인공지능 | 약 인공지능 |
|---|---|
| 사람과 같은 지능 | 특정 문제를 해결하는 지능적 행동|
| 마음을 가지고 사람처럼 느끼면서 지능적으로 행동하는 기계 | 사람의 지능적 행동을 흉내 낼 수 있는 수준 |
| 추론, 문제해결, 판단, 계획, 의사소통, 자아 의식(self-awareness), 감정(sentiement), 양심(conscience) | 대부분의 인공지능 접근 방향 |
| 튜링 테스트 | 중국인 방 사고실험(Chinese room thought experiment) |

## 튜링 테스트
* 개념
  * 인공지능의 우수성을 측정하는 실험
  * 1950년 영국 수학자인 앨런 튜링이 제안한 방법
  * 질의 응답 등을 통해 기계가 인간 수준의 지능이 있는지 가려냄
  * 기계인지 인간인지 가려내지 못하면 튜링 테스트 통과
<br><Br>
* 역사
  * <u>**1966년 '일라이자'(ELIZA)**</u>
    * 튜링 테스트에 도전해 어느 정도 성과를 거둔 사례(MIT)
    * 사용자가 입력하는 말을 분석해 키워드를 찾아낸 후 이를 바탕으로 컴퓨터의 반응을 생성하는 식으로 작동
<br><br>
  * <u>**정신과 환자 모방한 '패리'**</u>
    * 1972년 개발된 프로그램(스탠퍼드)
    * 편집성 정신분열증 환자의 반응을 흉내 내도록 설계
    * 48%는 프로그램이 정신 분열증 환자로 판정
<br><br>
  * <u>**'생각하는 인공지능' 기준 첫 통과한 '유진'**</u>
    * 튜링 테스트를 통과한 첫 사례
    * 튜링 테스트 2014 행사에서 통과
    * '유진 구스트만'이라는 슈퍼컴퓨터에서 돌아가는 '유진'이라는 프로그램이 이 기준을 통과
<br><br>
## 중국인 방 실험
* <u>**'튜링테스트는 인공지능이 아니다'라는 논리를 펴기 위함**</u>
* 해당 이론으로 인공지능이 더욱 더 발전하게 되는 계기가 되었다
<br><br>
## AI, ML, DL
* Artificial Intelligence
  * Programs with the ability to learn and reason like humans
* Machine Learning
  * Algorithms with the ability to learn without being explicitly programmed
* Deep Learning
  * Subset of machine Learning in which Artificial neural networks adapt and learn from vast amounts of data
<br><br>
## 주요 적용 기술
* 전산 신경 과학(Computational Neuroscience)
  * 신경계의 기능을 이해하기 위해 컴퓨터 시뮬레이션과 수학적 모델과 같은 전산 기술을 이용
* 로보스틱 인지로봇 공학
  * 외부환경을 인식(Perception)하고, 스스로 상황을 판단(Cognition)하여, 자율적으로 동작(Manipulation)하는 로봇
* 패턴 인식
  * 센싱된 대상을 인식하는 문제
* 머신러닝
  * 컴퓨터가 학습할 수 있도록 하는 알고리즘과 기술을 개발하는 분야
  * 회귀, 분류, 군집화 등
* 딥러닝
  * 여러 비선형 변환 기법의 조합을 통해 높은 수준의 추상화를 시도하는 기계학습 알고리즘 집합

## 기계학습
* 정의
  * 프로그램의 성능을 주어진 데이터나 과거 결과나 경험을 이용하여 향상 시키는 것
  * 주어진 데이터를 기반으로 한 방법을 계속 향상시키기 위해 노력
  * 데이터 셋을 분석, 문제해결을 위한 알고리즘 개발, 개선
    * 최근에는 딥러닝을 통해 빠르게 발전하고 있음
<Br><br>
* 통계학과 다른점
  * 알고리즘 성능을 중요하게 생각
  * 과거 경험등을 통계학보다 중요하게 생각
<br><br>
* 프로그램 방식과 차이점<br>
    |일반적 프로그램 | 기계학습 |
    |---|---|
    | * 사람이 설계/개발 | * 사람이 설계/개발 |
    | * 의도한 대로 출력 | * 알고리즘은 기계가 최종 학습/개발 |
    | | * 데이터에 따른 출력 |

## 기계학습에서 주로 다루는 문제들
* 
    | 구분 | 내용 | 예시 |
    |---|---|---|
    |분류(Classification)|데이터의 패턴을 보고 특정 결과로 분류|스팸필터, 이상현상 탐지|
    |회귀(Regression)|데이터의 패턴이 앞으로 어떻게 변할지 예측|주가 예측 등|
    |군집(Clustering)|결과들이 어떤 특징을 가진 결과에 속하는지 유사한 것들끼리 군집화|유사 성향, 긍정*부정 군집화|
    |차원 축소(Dimension Reduction)|매우 복잡한 차원의 문제를 축소하여 단순화 시킴|기계학습을 효율화 하기위한 기법으로 자주 사용|
    |전략(Strategy Learning)|최선의 전략을 찾는 문제|게임, 마케팅, 알파고|
    |연관(Association)|아이템, 항목간의 연관관계|마트에서 물품배치 예시|
<br><br>
## 기계학습 유형
* | 구분 | 내용 |
  |---|---|
  | 지도학습 | 모든 학습 데이터에 Label(결과)이 주어짐 |
  | (Supervised Learning) | Classification, Regression |
  | 반 지도 학습 | 일부 학습 데이터에만 Label(결과)이 주어짐 |
  | (Semi-Supervised Learning) | Classification, Clustering |
  | 비지도 학습 | 학습데이터에 Label(결과)이 없음 |
  | (UnSupervised Learning) | Clustering, Dimension, Reduction, Association |
  | 강화학습 | 주어진 행동에 대해서 Rewards를 부여받음 |
  | (Reinforcement Learning) | Strategy Learning |

---
# 2. AI 사례분석
## 다양한 분야에서 활용
* 얼굴인식
* 사물인식 및 추적
* 영상 분류 등 영상 인식, 음성인식
* 지능 로봇
* 질병 및 고장의 진단
* 비즈니스 의사 결정
* 무인 자동차
* 기계 번역
* 컴퓨터 비전
<br><br>
## 스팸 메일 필터
* **1단계 : 메일링 리스트로 필터링**
  * 상대방이 메일 주소를 바꾸는 경우 무의미<br><br>
* **2단계 : 메일의 제목이나 내용으로 필터링**
  * 단어를 변경하거나 바꾸는 경우 무의미<br><br>
* **3단계 : 컴퓨터에게 스팸 메일과 스팸 메일이 아닌 것을 보여주며 학습**
  * 데이터를 통해 컴퓨터가 자동으로 필터링을 수행
<br><br>
## 이미지 분류
* 글씨 인식
  * 데이터 전처리 없이 분류하고자 할 경우
  * 일반적인 분류 기법에는 공간의 배치와 입력 특징 구조 고려가 없음
  * 특징을 재배치하여 분류를 수행하여도 같은 결과를 볼 수 있음
<br><br>
## 이미지 인식
* 얼굴 검출
  * 하나의 이미지를 위치와 범위, 방향이 다른 여러 개의 겹쳐지는 작은 패치로 분할
  * 각 패치를 얼굴과 같은 텍스처를 포함하는지 분류

---
# 3. AI 알고리즘의 이해하기
## ML 문제해결의 절차
* | 단계 | 내용 | 담당자 |
  |---|---|---|
  | 문제 이해 | 어떤 문제를 풀어야 하는지 파악 | 도메인 전문가 |
  | 데이터 이해(탐색) | 문제를 위해 사용할 수 있는 데이터가 어떤 것들이 있고 어떤 타입이고 어떤 특성이 있는지 파악 | 도메인 전문가 + 기술전문가 |
  | 데이터 준비(전처리) | 학습 데이터와 테스트 데이터 생성을 목표로 불완전한 데이터 처리와 턱성 정의 | 기술 전문가 |
  | 모델링 | 머신러닝 모델 생성 | 기술 전문가 |
  | 평가 | 생성된 모델 성능 평가 | 기술 전문가 |
  | 배포 | 실제 환경에 모델을 적용하여 시스템 화 | 서비스 운영/관리자 |

## 데이터 처리
* 인공지능, 기계학습에서 데이터 처리 기법을 Feature Engineering 이라고 한다.
    <br><Br> 
  1) 결측값 처리
    - 결측값 : 입력되지 않은 값, Null, 중간에 빠진 값
    - 결측값 처리 여부가 인공지능 학습에 영향을 미친다
    - Mean(평균), Median(중앙값), Mode(최빈값) 등을 사용할 수 있음
    <br><Br>
   2) 원 핫 인코딩(one-hot encoding)
  * | id  | color |One Hot Encoding   |id   |color_red|color_blue|color_green| 
    |:---:|:---:  |---                |:---:|:---:    |:---:     |:---:      |
    | 1   | red   |                   | 1   | 1       |0         |0          |
    | 2   | blue  |                   | 2   | 0       |1         |0          |
    | 3   | green |                   | 3   | 0       |0         |1          |
    | 4   | blue  |                   | 4   | 0       |1         |0          |
  
* 인공지능, 기계학습에서 데이터 처리 기법을 Feature Engineering 이라고 한다.

* 정규화
  * 특정 데이터로 인해서 전체 학습 데이터가 편향될 수 있으므로 이를 방지 할 수 있도록 데이터 조정이 필요한데 이를 정규화 라고 한다
  * Rescaling(min-max normalization)<br>
    : 다양한 범주의 feature를 [0,1] 또는 [-1,1] 범위로 스케일링 하는 가장 간단한 방법
  * Standardization(Z-score Normalization) 표준정규화<br>
    : 각 feature가 평균이 0이고 표준편차가 1인 분포를 가지게 한다

* 신규 특성 생성
  * 특성 A, B가 있으면 A * B 을 새로운 특성으로 추가함

* 변환
  * 지수적으로 증가하는 데이터의 경우는 Log를 사용하여 정규분포에 따르는 데이터로 변환

* 비닝(Binning)
  * 특성들의 값을 여러 개에 Bin에 할당해서 분리하는 경우
  * 강수량 데이터를 비가 왔는지 안왔는지로 단순화
  * 공간을 줄여서 오버 피팅의 가능성을 줄일 수 있다.

## 지도 학습
* 지도 학습
  * input에 맞추어 output을 mapping하는 function을 만드는 것
  * 주어진 input, output으로 부터 function을 학습함
  * Training Data / Test Data
  * Regression
  * Classification

## SVM(Support Vector Machine)
* 클래스 별 데이터를 가장 잘 구분하는 최적의 하이퍼 플레인(Hyperplane)을 찾는 알고리즘
* 하이퍼 플레인
  * 데이터가 분포되어 있는 n차원 피처 공간을 두 공간으로 나누는 n-1 차원의 평면
  * 예) 2차원 피처 공간에서 하이퍼 플레인은 '선'(line), 3차원 피처 공간에서 하이퍼 플레인은 '평면'(surface)

## SVM(Support Vector Machine) MultiClass
* 일대일 방법은 일대다 방법보다 분류기가 훨씬 더 많이 만들어 진다.
  * 일대일 : K(1-K)/2
  * 일대다 : K
* 일대 다 방법은 한 분류기를 학습시킬 때 학습 데이터로 전체 데이터를 사용하지만 일대일 방법은 대상이 되는 두 클래스에 대한 데이터만 사용함
  * 한 분류기를 학습하는 상황은 1:1이 HW 효율성이 더 좋음

## SVM(Support Vector Machine) Kernel
* 기본적으로 SVM은 선형식에 기반하고 있어 비선형 문제는 적합하지 않으나 공간을 변환(Transform)한 (커널 함수 사용)뒤에 SVM을 적용하는 것은 가능함
* 대표적인 커널 함수로는 다항식 커널, RBF 커널, 하이퍼볼릭 탄젠트 커널이 있다

## Decision Tree
* 정의
  * 모형의 구축과정을 나무 형태로 표현하여 대상이 되는 집단을 몇개의 소집단으로 구분하는 분류 및 예측 기법
* | 구성요소 | 설명 |
  |---|---|
  | Root Node | Tree 시작 노드, 최상단 노드 |
  | Parent Node | Child Node의 상위 Node |
  | Child Node | 하나이상의 Node로부터 분리되어 나간 2개 이상의 Node |
  | Internal Node | Root Node와 Leaf Node 사이의 모든 마디 |
  | Branch | Node와 Node 사이의 선 |
  | Leaf Node | Tree의 끝에 위치 |
* 의사결정 트리 분류기는 트리 모양의 순차 형 다이어그램을 통해 주어진 데이터를 분류
  * 트리의 루트부터 시작해서 모든 중간 노드들은 의사 결정사항(조건)
  * 트리의 맨끝에 있는 리프 노드는 의사결정 사항에 따른 최종 결과
* 의사결정 트리 분류기의 동작은 의사결정 트리를 생성하는 학습 단계와 생성된 의사결정 트리에 따라 주어진 데이터를 분류하는 분류 단계로 구분
  * 대표적인 트리 생성 알고리즘 : ID2, C4.5, CART, CHAID

## Decision Tree(CART : Classification and Regression Tree)
* 학습데이터를 사용하여 각 노드를 왼쪽 자식 노드와 오른쪽 자식 노드로 분할해 가며 트리를 생성
* 분할
  * 각 파티션 단계에서 가장 중요한 피처와 해당 피처의 값의 조합을 탐욕적(Greedy)방식으로 탐색
  * Global Optima가 아니라 Local Optima를 우선 고려
  * Gini, Entropy 같은 분할하는 방법을 사용
* 정지 : 분할과정은 다음과 같은 조건이 만족되면 중지
  * 분할 후 만들어질 노드의 샘플수가 일정 수준 이하일 때
  * 트리의 깊이가 일정 수준 이상일 때
  
## LogisticRegression
* 로지스틱 회귀 분류기는 로지스틱 함수(시그모이드 함수)를 사용하는 분류기
* 로지스틱 함수
  * 입력된 값에 0과 1 사이 값을 할당하는 함수
* 로지스틱 회귀에서 함수의 입력인 z는 피처 x의 가중치 합(입력 피처가 선형변환)
* 목적 공간에 완벽하게 매핑하기 어려워 절편을 식에 추가해서 사용함
* 학습의 목적은 Feature를 잘 변환해 줄 수 있는 w을 찾는 것
* z= w_0 + w_1*x_1 + w_2*x_2 + ... + w_n*x_n = w^T*x

## Neural network
* 뉴럴 네트워크(인공 신경망)는 인간의 신경 세포 구조에서 영감을 받음
* 인간의 몸에는 많은 신경 세포(neuron)가 존재하며 이들은 서로 시냅스(synapse)를 통해 연결되어 있음
* 각 신경 세포는 어떤 전기적인 자극이 들어오면 각 세포의 특성에 따라 다르게 반응하고 새로운 전기적 자극을 만들어 연결된 신경세포에 전달
* 뉴럴 네트워크의 기본 요소가 되는 퍼셉트론(Perceptron)은 신경세포 하나를 나타냄
* 퍼셉트론은 값들(벡터)을 입력 받아 가중치에 따라 합산한 뒤 활성화 함수(Activation Function)값을 다음 퍼셉트론에 전달

* 뉴럴 네트워크는 퍼셉트론으로 레이어(층)를 구성해 쌓아가는 구조
  * Multi Layer Perceptron 이라고도 불림
* 레이어별 이름 존재
  * InputLayer : 피처 값을 그대로 입력받는 첫 레이어
  * OutputLayer : 최종 출력값(예측값)을 반환하는 레이어
  * HiddenLayer : InputLayer와 OutputLayer 사이 레이어

* Hidden Layer가 3개 이상이면 딥 뉴럴네트워크라고 부른다
  * 층이 많아서 그만큼 깊다 라는 의미
* Hidden Layer 수가 많아질 수록 그만큼 더 복잡한 피처 공간을 표현할 수 있음

* CNN(Convolutional Neural Network), RNN(Recurrent Neural Network) 모두 Deep Neural Network의 종류

## 비지도 학습
* 어떠한 특정 규칙이 없는 데이터 셋에서 무언가의 규칙을 찾는 방법

## 비지도 학습(클러스터링)
* 데이터세트를 몇 개의 클러스터(그룹)으로 나누는 것을 말함
  * 데이터 샘플들을 서로 비슷한(가까운)것끼리 그룹화 함
* 학습 과정에서 보통 레이블을 사용하지 않기 때문에 '비지도학습'에 해당
* 클러스터링 수행 시 기준을 정량적으로 정의해야 함
  * 각 개체간 거리를 거리 함수로 측정
    * 유클리디언 거리(EuclideanDistance)
    * 맨하탄거리(택시거리)(ManhattanDistance)
  
## 비지도 학습(K-means 알고리즘)
1. 군집의 수 K를 정의
2. 초기 K개 군집의 중심(Centroids) 선택
3. 각 관측 값들을 가장 가까운 중심의 군집에 할당
4. 새로운 군집의 중심 계산
5. 재정의 된 중심 값 기준으로 다시 거리 기반의 군집 재 분류
6. 군집 경계가 변경되지 않을 때 까지 반복

## 강화 학습
* 학습의 규칙
  * 우리는 과거 경험으로 부터 학습
  * 주어진 환경과 interaction, 결과가 얼마나 큰 영향을 미치는지를 알게된다
  * 경험에 대한 긍정적인 피드백, 부정적인 결과 모두 학습과 행동에 영향을 미침

* 강화 학습
  * interaction에 기반한 Computational approach
  * 완전한 지도 학습이라고 보기 어려움
  * 행동이 미래 reward에 영향을 미침


